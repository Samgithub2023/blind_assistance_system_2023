{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b69b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2 import model_zoo\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the panoptic segmentation model and predictor here\n",
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Load the navigable path extraction function here\n",
    "navigable_class_id = 43\n",
    "stairs_class_id = 27\n",
    "\n",
    "# Load an example video (you need to provide the video path)\n",
    "video_path = \"final_object_vid.mp4\"  # Replace with your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#import imageio\n",
    "def extract_navigable_path(panoptic_seg, segments_info, navigable_class_id):\n",
    "    navigable_mask = np.zeros_like(panoptic_seg)\n",
    "    for segment_info in segments_info:\n",
    "        if segment_info[\"category_id\"] == navigable_class_id:\n",
    "            segment_id = segment_info[\"id\"]\n",
    "            navigable_mask[panoptic_seg == segment_id] = 1\n",
    "    return navigable_mask\n",
    "\n",
    "#cap = imageio.get_reader(video_path)\n",
    "Upanoptic_seg=[]\n",
    "Usegments_info=[]\n",
    "Unavigable_mask=[]\n",
    "# Define the output video settings\n",
    "output_path = \"blind_project_result33.mp4\"\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"XVID\"), 10, (frame_width, frame_height))\n",
    "\n",
    "arrow_center = (frame_width // 2, frame_height - 30)\n",
    "arrow_length = 40\n",
    "arrow_color = (0, 255, 0)  # \n",
    "\n",
    "# Define the region of interest dimensions\n",
    "roi_width = 160  # Specify the width of the region of interest\n",
    "roi_height = 160  # Specify the height of the region of interest\n",
    "if cap.isOpened():\n",
    "    print(\"video capture is working\")\n",
    "    #break\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    print(\"Reading frame:\", ret)\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Define the image dimensions\n",
    "    image_width = frame.shape[1]\n",
    "    image_height = frame.shape[0]\n",
    "\n",
    "    # Create an empty grid\n",
    "    grid = np.zeros((image_height, image_width), dtype=bool)\n",
    "\n",
    "    # Set the ROI (region of interest) to True\n",
    "    start_x = (image_width - roi_width) // 2\n",
    "    end_x = start_x + roi_width\n",
    "    start_y = image_height - roi_height\n",
    "    end_y = image_height\n",
    "    grid[start_y:end_y, start_x:end_x] = True\n",
    "\n",
    "    # Define the navigable path mask and perform other processing here\n",
    "    panoptic_seg, segments_info = predictor(frame)[\"panoptic_seg\"]\n",
    "    navigable_mask = extract_navigable_path(panoptic_seg, segments_info, navigable_class_id)\n",
    "    Upanoptic_seg.append(panoptic_seg)\n",
    "    Usegments_info.append(segments_info)\n",
    "    Unavigable_mask.append(navigable_mask)\n",
    "    stairs_mask = np.zeros_like(panoptic_seg)\n",
    "    for segment_info in segments_info:\n",
    "        if segment_info[\"category_id\"] == stairs_class_id:\n",
    "            segment_id = segment_info[\"id\"]\n",
    "            stairs_mask[panoptic_seg == segment_id] = 1\n",
    "    overlay = np.zeros_like(frame)\n",
    "    overlay[navigable_mask] = [0, 0, 255]  # Red color for navigable path\n",
    "    overlay[grid] = [255, 0, 0]  # Blue color for grid\n",
    "\n",
    "    # Blend the overlay with the original frame\n",
    "    output_frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)\n",
    "\n",
    "    stairs_in_roi = np.any(stairs_mask[start_y:end_y, start_x:end_x])\n",
    "    if stairs_in_roi:\n",
    "        result_text = \"Stairs detected ahead.\"\n",
    "        # Load the image\n",
    "        stairs = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur for noise reduction\n",
    "        blurred = cv2.GaussianBlur(stairs, (5, 5), 0)\n",
    "\n",
    "    # Perform edge detection using the Canny edge detector\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Perform line detection using the Hough Transform\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "    # Calculate the mean orientation of detected lines\n",
    "        orientations = []\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "            orientations.append(angle)\n",
    "\n",
    "        mean_orientation = np.mean(orientations)\n",
    "\n",
    "# Define a threshold to determine the predominant direction\n",
    "        threshold_angle = 45\n",
    "\n",
    "        if abs(mean_orientation) < threshold_angle:\n",
    "            direction = \"Up\"\n",
    "        else:\n",
    "            direction = \"Down\"\n",
    "\n",
    "        cv2.putText(output_frame, \"{} stairs ahead\".format(direction), (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        result_text = \"No stairs detected in the ROI.\"\n",
    "\n",
    "    # Overlay the navigable mask and grid on the frame\n",
    "    \n",
    "\n",
    "    # Check if any non navigable path segment is present in the ROI\n",
    "    non_navigable_pixels = ~navigable_mask[start_y:end_y, start_x:end_x] & grid[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    if np.any(non_navigable_pixels):\n",
    "        print(\"Person cannot move forward.\")\n",
    "        half_width = grid.shape[1] // 2\n",
    "\n",
    "        can_move_forward=False\n",
    "\n",
    "        # Divide the grid into two halves (left and right)\n",
    "        half_width = grid.shape[1] // 2\n",
    "\n",
    "        left_half = grid[:, :half_width]\n",
    "        right_half = grid[:, half_width:]\n",
    "\n",
    "# Check left half for navigable path\n",
    "        left_half_start_x = 0\n",
    "        left_half_end_x = half_width\n",
    "\n",
    "        left_half_navigable_mask = navigable_mask[:, left_half_start_x:left_half_end_x]\n",
    "        left_half_grid = left_half\n",
    "\n",
    "        left_non_navigable_pixels = ~left_half_navigable_mask & left_half_grid\n",
    "\n",
    "        if np.any(left_non_navigable_pixels):\n",
    "            left=False\n",
    "            print(\"Object detected on the left. Move right.\")\n",
    "        else:\n",
    "            left=True\n",
    "            print(\"Left half: Person can move forward.\")\n",
    "\n",
    "        cv2.putText(output_frame, \"Can move left :{}\".format(left), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "# Check right half for navigable path\n",
    "        right_half_start_x = half_width\n",
    "        right_half_end_x = grid.shape[1]\n",
    "\n",
    "        right_half_navigable_mask = navigable_mask[:, right_half_start_x:right_half_end_x]\n",
    "        right_half_grid = right_half\n",
    "\n",
    "        right_non_navigable_pixels = ~right_half_navigable_mask & right_half_grid\n",
    "\n",
    "        if np.any(right_non_navigable_pixels):\n",
    "            print(\"Right half: Person cannot move forward.\")\n",
    "            right=False\n",
    "            \n",
    "        else:\n",
    "            right=True\n",
    "            print(\"Right half: Person can move forward.\")\n",
    "\n",
    "        cv2.putText(output_frame, \"Can move right :{}\".format(right), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        if (right == False) and (left == False):\n",
    "            cv2.putText(output_frame, \"!!!STOP!!!\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 2)\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Person can move forward.\")\n",
    "        can_move_forward=True\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    cv2.putText(output_frame, \"Can move :{}\".format(can_move_forward), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    quadrant_width = 80\n",
    "    quadrant_height = 80\n",
    "\n",
    "    quadrant_lower_left = grid[end_y-quadrant_height:end_y, start_x:start_x+quadrant_width]\n",
    "    quadrant_lower_right = grid[end_y-quadrant_height:end_y, start_x+quadrant_width:end_x]\n",
    "\n",
    "    #non_navigable_pixels = ~navigable_mask[start_y:end_y, start_x:end_x] & grid[start_y:end_y, start_x:end_x]\n",
    "\n",
    "\n",
    "    lower_left_non_navigable_pixels = ~navigable_mask[start_y+quadrant_height:end_y, start_x:start_x+quadrant_width]& quadrant_lower_left\n",
    "    lower_right_non_navigable_pixels = ~navigable_mask[start_y+quadrant_height:end_y, start_x+quadrant_width:end_x]& quadrant_lower_right\n",
    "    #if true \n",
    "    \n",
    "    \n",
    "    arrow_frame = output_frame.copy()\n",
    "    if can_move_forward:\n",
    "        arrow_tip = (arrow_center[0], start_y)\n",
    "        cv2.arrowedLine(arrow_frame, arrow_center, arrow_tip, arrow_color, 7)\n",
    "    elif left:\n",
    "\n",
    "        if np.any(lower_right_non_navigable_pixels):\n",
    "            arrow_tip = (start_x,start_y+((end_y-start_y)//2))\n",
    "        else:\n",
    "            arrow_tip =  (start_x, start_y)\n",
    "            \n",
    "\n",
    "        cv2.arrowedLine(arrow_frame, arrow_center, arrow_tip, arrow_color, 7)\n",
    "    elif right:\n",
    "\n",
    "        if np.any(lower_left_non_navigable_pixels):\n",
    "            arrow_tip = (end_x,start_y+((end_y-start_y)//2))\n",
    "        else:\n",
    "            arrow_tip = (end_x,start_y)\n",
    "        cv2.arrowedLine(arrow_frame, arrow_center, arrow_tip, arrow_color, 7)\n",
    "\n",
    "\n",
    "    out.write(arrow_frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
